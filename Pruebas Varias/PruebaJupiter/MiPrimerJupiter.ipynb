{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/22/2021 21:29:04 *) Iniciando programa normalizacion \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "''' TF_CPP_MIN_LOG_LEVEL\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printed\n",
    "3 = INFO, WARNING, and ERROR messages are not printed\n",
    "'''\n",
    "'''\n",
    "print('backend :', keras.backend.backend())\n",
    "print('keras version :', keras.__version__)\n",
    "'''\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy\n",
    "#import datetime\n",
    "import scipy\n",
    "#import shutil\n",
    "import pxpLibreriaDataFrame as pd_pxp\n",
    "import pxpLibreriaTURNOS as pxpLibreriaLocal\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.utils import class_weight\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "from contextlib import redirect_stdout\n",
    "from pickle import dump\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "logPrograma = []\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) Iniciando programa normalizacion \", True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Parametrizo\n",
    "archivoOriginal = \"Turnos_Tomados_Nov2020_mar2021_8.csv\"\n",
    "archivoBalanceado = 'Turnos_Tomados_Balanceados.csv'\n",
    "archivoGuardaTransformaciones = \"Turnos_Transformaciones.pkl\"\n",
    "archivoInfoBalanceo = \"Turnos_Info_Balanceo.txt\"\n",
    "\n",
    "columnaObjetivo = 'AUSENTE'\n",
    "mostrarGraficos = True\n",
    "mostrarGraficoMejoresCols = False\n",
    "\n",
    "metodoBalanceo = 'SMOTE-TOMEK'  # 'RUS' 'NEARMISS'  'ROS'  'SMOTE' 'SMOTE-TOMEK' 'NONE'\n",
    "\n",
    "##antes\n",
    "##################################################################\n",
    "# Parametrizo columnas (['pclass', 'sex', 'embarked'], OneHotEncoder())\n",
    "column_trans = ColumnTransformer(\n",
    "    [\n",
    "        ('diasem', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['DIASEMANA_ID'])\n",
    "        #  , ('Acme', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['ACME_ID'])\n",
    "        , ('Sexo', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['SEXO_ID'])\n",
    "        , ('tipo_acme', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['TIPO_ACME_ID'])\n",
    "        , ('ubicacion', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['UBICACION_ID'])\n",
    "        , ('agenda', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['AGENDA_ID'])\n",
    "        #  ('rangoant', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['RANGO_ANTIGUEDAD'])\n",
    "        , ('servicio', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['SERVICIO_ID'])\n",
    "        , ('sectorgroup', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['GRUPO_SECTOR_ID'])\n",
    "        , ('sector', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['SECTOR_ID'])\n",
    "        , ('rangohora', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['RANGO_HORARIO_ID'])\n",
    "        , ('area', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['AREA_ID'])\n",
    "        , ('rango4hs', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['RANGO_4HS_ID'])\n",
    "        # , ('institu', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['INSTITUCION_ID'])\n",
    "        #  , ('decadas', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['EDAD_DECADAS'])\n",
    "    ],\n",
    "    remainder='passthrough')\n",
    "# DIASEMANA_ID\tACME_ID\tSEXO_ID\taparicion\tTIPO_ACME_ID\tUBICACION_ID\tEDAD_PACIENTE_ID\tRANGO_ANTIGUEDAD\n",
    "\n",
    "##despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/22/2021 21:29:30 *) Levantando datos de Turnos_Tomados_Nov2020_mar2021_8.csv\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "# Levanto los datos\n",
    "###################################################################\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) Levantando datos de \" + archivoOriginal, True)]\n",
    "df_leida = pd.read_csv(archivoOriginal, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180465, 27)\n"
     ]
    }
   ],
   "source": [
    "print(df_leida.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "   classes = df_leida[columnaObjetivo].values\n",
    "    unique, counts = numpy.unique(classes, return_counts=True)\n",
    "\n",
    "    plt.bar(unique, counts)\n",
    "    plt.title('Class Frequency')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if mostrarGraficoMejoresCols:\n",
    "    classes = df_leida[columnaObjetivo].values\n",
    "    unique, counts = numpy.unique(classes, return_counts=True)\n",
    "\n",
    "    plt.bar(unique, counts)\n",
    "    plt.title('Class Frequency')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if mostrarGraficoMejoresCols:\n",
    "    pd_pxp.ExplorarDatosPrevios(df_leida)\n",
    "\n",
    "# [infocol] Guardo informacion de columnas para registro en el log de texto\n",
    "df_Informacion = pd.DataFrame()\n",
    "df_Informacion[\"Columnas originales\"] = df_leida.columns.tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/22/2021 21:31:09 *) Inicio PreProcesoDataFrame C:\\Users\\pasca\\ProyectosJupiter\\PruebaJupiter\\pxpLibreriaTURNOS.py\n",
      "05/22/2021 21:31:09 *) Transformando Columnas \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_Informacion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-011d5b589661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# [infocol] Guardo informacion de columnas para registro en el log de texto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mColumnasResultantes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_Informacion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdf_Informacion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Columnas originales\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_leida\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mColumnasResultantes\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf_Informacion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Columnas originales\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Informacion' is not defined"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# Procesamiento b√°sico del Dataframe\n",
    "df_leida = pxpLibreriaLocal.PreProcesoDataFrame(logPrograma, df_leida)\n",
    "\n",
    "\n",
    "# [infocol] Guardo informacion de columnas para registro en el log de texto\n",
    "ColumnasResultantes = []\n",
    "for i in df_Informacion.index:\n",
    "    if df_Informacion[\"Columnas originales\"][i] in df_leida.columns:\n",
    "        ColumnasResultantes += [df_Informacion[\"Columnas originales\"][i]]\n",
    "    else:\n",
    "        ColumnasResultantes += ['-----']\n",
    "df_Informacion[\"Columnas Resultantes\"] = ColumnasResultantes\n",
    "\n",
    "################ TRANSFORMACION\n",
    "coltra = column_trans.fit(df_leida)\n",
    "transformacion = column_trans.transform(df_leida)\n",
    "# La transformacion puede devolver distintas cosas... no uso pd.DataFrame.sparse.from_spmatrix por que funciona pero adentro queda sparce igual\n",
    "if type(transformacion) == scipy.sparse.csr.csr_matrix:\n",
    "    transformacion = transformacion.toarray()\n",
    "df_transformada = pd.DataFrame(transformacion, columns=coltra.get_feature_names())\n",
    "\n",
    "################# CONTROL DE NORMALIZACION\n",
    "for unacol in df_transformada.columns:\n",
    "    if (df_transformada[unacol].max() > 1) or (df_transformada[unacol].min() < 0):\n",
    "        print('*** ATENCION ***\\nColumna con valores no normalizados: ' + unacol)\n",
    "        mensaje = 'Minimo {minimo}  Maximo {maximo} '\n",
    "        mensaje = mensaje.format(minimo=df_transformada[unacol].min(), maximo=df_transformada[unacol].max())\n",
    "        print(mensaje)\n",
    "        input(\"Esperando ....\")\n",
    "\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) Fin PreProcesoDataFrame \", True)]\n",
    "\n",
    "############################ //// BALANCEO INICIO\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) Iniciando Balanceo  \" + metodoBalanceo, True)]\n",
    "df_in = pd.DataFrame(df_transformada).drop([columnaObjetivo], axis=1)  # Todos menos lo que voy a predecir\n",
    "df_out = pd.DataFrame(df_transformada[columnaObjetivo])  # Lo que voy a predecir\n",
    "\n",
    "distribuciones = pd_pxp.mostrarDistribucionDelObjetivo(df_out, columnaObjetivo, \"ANTES DEL BALANCEO\")\n",
    "if metodoBalanceo == 'RUS':\n",
    "    # ---------- Submuestreo RUS:  Elimina muestras de la clase m√°s representada aleatoriamente\n",
    "    rus = RandomUnderSampler()  # random_state = 0\n",
    "    df_in, df_out = rus.fit_resample(df_in, df_out)\n",
    "elif metodoBalanceo == 'NEARMISS':\n",
    "    # ---------- Submuestreo NearMiss : Elimina las muestras m√°s cercanas de la clase m√°s representada\n",
    "    nm = NearMiss()\n",
    "    df_in, df_out = nm.fit_resample(df_in, df_out)\n",
    "elif metodoBalanceo == 'ROS':\n",
    "    # ---------- sobremuestreo: ROS. Duplica muestras de la clase menos representadas\n",
    "    ros = RandomOverSampler()  # random_state = 0\n",
    "    df_in, df_out = ros.fit_resample(df_in, df_out)\n",
    "elif metodoBalanceo == 'SMOTE':\n",
    "    # ---------- sobremuestreo: SMOTE. Genera nuevas muestras sint√©ticas\n",
    "    smote = SMOTE()\n",
    "    df_in, df_out = smote.fit_resample(df_in, df_out)\n",
    "elif metodoBalanceo == 'SMOTE-TOMEK':\n",
    "    # ---------- smote-Tomek. Sobremuestreo con Smote seguido de un submuestreo con Uniones de Tomek\n",
    "    smoteT = SMOTETomek()  # random_state = 0\n",
    "    df_in, df_out = smoteT.fit_resample(df_in, df_out)\n",
    "else:\n",
    "    print(\"balanceo no implementado o desconocido :\" + metodoBalanceo)\n",
    "\n",
    "df_transformada = df_in\n",
    "df_transformada[columnaObjetivo] = df_out.values;\n",
    "distribuciones += pd_pxp.mostrarDistribucionDelObjetivo(df_out, columnaObjetivo, \"DESPUES DEL BALANCEO\")\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) Fin del Balanceo  \" + metodoBalanceo, True)]\n",
    "############################# //// BALANCEO FINAL\n",
    "\n",
    "\n",
    "\n",
    "###################################  GUARDO ARCHIVOS\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) GUARDANDO ARCHIVO BALANCEADO \", True)]\n",
    "df_transformada.to_csv(archivoBalanceado, ';')\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) Guardando Transformaciones \", True)]\n",
    "dump(coltra, open(archivoGuardaTransformaciones, \"wb\"))\n",
    "\n",
    "logPrograma += [pd_pxp.registroMomento(\"*) Armando resultados finales \", True)]\n",
    "fileMem = io.StringIO()\n",
    "with redirect_stdout(fileMem):\n",
    "    print('#' * 10, \"Archivos en uso \", '#' * 10)\n",
    "    print(\"* Archivos de entrada: \")\n",
    "    print(' - ' + archivoOriginal)\n",
    "    print(\"* Archivos de salida : \")\n",
    "    print(' - ' + archivoBalanceado)\n",
    "    print(' - ' + archivoInfoBalanceo)\n",
    "    print(' - ' + archivoGuardaTransformaciones)\n",
    "    print('#' * 10, \"Balanceo\", '#' * 10)\n",
    "    print(\" Metodo de Balanceo: \"+metodoBalanceo)\n",
    "    print('#' * 10, \"Distribuciones\", '#' * 10)\n",
    "    print(distribuciones)\n",
    "    print('#' * 10, \"Columnas\", '#' * 10)\n",
    "    print(df_Informacion.head)\n",
    "    print('#' * 10, \"Detalle de transformaciones\", '#' * 10)\n",
    "    print(column_trans)\n",
    "    print('#' * 10, \"Estructura de  \"+archivoBalanceado, '#' * 10)\n",
    "    print(df_transformada.columns.tolist())\n",
    "    print('#' * 10, \"Log de performance\", '#' * 10)\n",
    "    logPrograma += [\n",
    "        pd_pxp.registroMomento(\"*) FIN DEL PROCESO \", False)]  # no lo muestro por pantalla por que es stdout un string\n",
    "    for mom in logPrograma:\n",
    "        print(mom)\n",
    "\n",
    "# print(fileMem.getvalue())\n",
    "with open(archivoInfoBalanceo, 'w') as fileDisk:\n",
    "    fileDisk.write(fileMem.getvalue())  # Lo abro con w entonces lo pisa\n",
    "\n",
    "# Imprimo\n",
    "import winsound\n",
    "\n",
    "winsound.Beep(940, 500)\n",
    "winsound.Beep(340, 500)\n",
    "\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
